{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dae-tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMO7OlE/4DvqyeA6UQBPKXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmyamanojna/CS6024-Algorithmic-Approaches-to-Computational-Biology-Project/blob/master/dae_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L93r0BORCtju"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import layers, losses\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "\r\n",
        "import os\r\n",
        "import seaborn as sns\r\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU2Ac7gBCxh6"
      },
      "source": [
        "%matplotlib inline\r\n",
        "plt.style.use('seaborn-notebook')\r\n",
        "sns.set(style=\"white\", color_codes=True)\r\n",
        "sns.set_context(\"paper\", rc={\"font.size\":14,\"axes.titlesize\":15,\"axes.labelsize\":20,'xtick.labelsize':14, 'ytick.labelsize':14})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UogfLX39DPXQ"
      },
      "source": [
        "np.random.seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpt3mQBaDRT1"
      },
      "source": [
        "pcos_df = pd.read_csv('common_normalized.csv')\r\n",
        "pcos_df = pcos_df.drop(['sample_id'], axis=1)\r\n",
        "# Split 10% test set randomly\r\n",
        "test_set_percent = 0.1\r\n",
        "pcos_test_df = pcos_df.sample(frac=test_set_percent)\r\n",
        "pcos_train_df = pcos_df.drop(pcos_test_df.index)\r\n",
        "print(pcos_train_df.head(2))\r\n",
        "print(pcos_test_df.head(2))\r\n",
        "print(pcos_train_df.shape)\r\n",
        "print(pcos_test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUGrPwc3DTDz"
      },
      "source": [
        "class Autoencoder(Model):\r\n",
        "  def __init__(self, latent_dim, original_dim):\r\n",
        "    super(Autoencoder, self).__init__()\r\n",
        "    self.latent_dim = latent_dim   \r\n",
        "    self.encoder = tf.keras.Sequential([layers.Dense(latent_dim, activation='relu')])\r\n",
        "    self.decoder = tf.keras.Sequential([layers.Dense(original_dim, activation='sigmoid')])\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    encoded = self.encoder(x)\r\n",
        "    decoded = self.decoder(encoded)\r\n",
        "    return decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKrWFLBUIWnb"
      },
      "source": [
        "original_dim = pcos_df.shape[1]\r\n",
        "latent_dim = 100\r\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoANX2ILIWZg"
      },
      "source": [
        "autoencoder = Autoencoder(latent_dim, original_dim) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8hD73uNDiDL"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzpjRcCuDlYO"
      },
      "source": [
        "hist = autoencoder.fit(pcos_train_df, pcos_train_df,\r\n",
        "                epochs=epochs,\r\n",
        "                shuffle=True,\r\n",
        "                batch_size=4,\r\n",
        "                validation_data=(pcos_test_df, pcos_test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlEkgXYMDw2o"
      },
      "source": [
        "# Visualize training performance\r\n",
        "history_df = pd.DataFrame(hist.history)\r\n",
        "ax = history_df.plot()\r\n",
        "ax.set_xlabel('Epochs')\r\n",
        "ax.set_ylabel('DAE Loss')\r\n",
        "fig = ax.get_figure()\r\n",
        "fig.savefig(\"hist_plot_file.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS9HoyREFD0B"
      },
      "source": [
        "pcos_df = pd.read_csv('common_normalized.csv')\r\n",
        "pcos_df = pcos_df.drop(['sample_id'], axis=1)\r\n",
        "# Split 10% test set randomly\r\n",
        "test_set_percent = 0.1\r\n",
        "pcos_test_df = pcos_df.sample(frac=test_set_percent)\r\n",
        "pcos_train_df = pcos_df.drop(pcos_test_df.index)\r\n",
        "print(pcos_train_df.head(2))\r\n",
        "print(pcos_test_df.head(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4mL5EyAL99r"
      },
      "source": [
        "pcos_train = pcos_train_df.to_numpy()\r\n",
        "pcos_test = pcos_test_df.to_numpy()\r\n",
        "print(pcos_train.shape)\r\n",
        "print(pcos_test.shape)\r\n",
        "pcos_train = pcos_train.reshape(157, 1669, 1)\r\n",
        "pcos_test = pcos_test.reshape(18, 1669, 1)\r\n",
        "print(pcos_train.shape)\r\n",
        "print(pcos_test.shape)\r\n",
        "\r\n",
        "# Adding random noise to the data\r\n",
        "noise_factor = 0.2\r\n",
        "pcos_train_noisy = pcos_train + noise_factor * tf.random.normal(shape=pcos_train.shape) \r\n",
        "pcos_test_noisy = pcos_test + noise_factor * tf.random.normal(shape=pcos_test.shape) \r\n",
        "\r\n",
        "pcos_train_noisy = tf.clip_by_value(pcos_train_noisy, clip_value_min=0., clip_value_max=1.)\r\n",
        "pcos_test_noisy = tf.clip_by_value(pcos_test_noisy, clip_value_min=0., clip_value_max=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69v4NpyNMTZt"
      },
      "source": [
        "class Denoise(Model):\r\n",
        "  def __init__(self):\r\n",
        "    super(Denoise, self).__init__()    \r\n",
        "    self.encoder = tf.keras.Sequential([layers.Dense(latent_dim, activation='relu')])\r\n",
        "    self.decoder = tf.keras.Sequential([layers.Dense(original_dim, activation='sigmoid')])\r\n",
        "    \r\n",
        "  def call(self, x):\r\n",
        "    encoded = self.encoder(x)\r\n",
        "    decoded = self.decoder(encoded)\r\n",
        "    return decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlHAX2IbPXo9"
      },
      "source": [
        "dae = Denoise()\r\n",
        "dae.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEWQoxBiPc0s"
      },
      "source": [
        "hist = dae.fit(pcos_train_noisy, pcos_train,\r\n",
        "                epochs=epochs,\r\n",
        "                shuffle=True,\r\n",
        "                batch_size=4,\r\n",
        "                validation_data=(pcos_test_noisy, pcos_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_TVAm8zPnqf"
      },
      "source": [
        "# Visualize training performance\r\n",
        "history_df = pd.DataFrame(hist.history)\r\n",
        "ax = history_df.plot()\r\n",
        "ax.set_xlabel('Epochs')\r\n",
        "ax.set_ylabel('DAE Loss')\r\n",
        "fig = ax.get_figure()\r\n",
        "fig.savefig(\"hist_plot_file_dae.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMiSRS8aSWYy"
      },
      "source": [
        "print(dae.encoder.summary())\r\n",
        "print(dae.decoder.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13tJAYz2Zkx-"
      },
      "source": [
        "encoded_imgs = dae.encoder(pcos_test).numpy()\r\n",
        "decoded_imgs = dae.decoder(encoded_imgs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqgYsBHnZxIV"
      },
      "source": [
        "print(encoded_imgs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVNzzCeBZ40a"
      },
      "source": [
        "plt.figure(figsize=(6, 6))\r\n",
        "plt.scatter(encoded_imgs[:][:][0], encoded_imgs[:][:][1])\r\n",
        "plt.xlabel('Latent Feature 1')\r\n",
        "plt.ylabel('Latent Feature 2')\r\n",
        "plt.savefig('node_activation_2_latent.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFXq94BeaRBF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}